import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from statsmodels.stats.outliers_influence import variance_inflation_factor
import warnings

# Suppress warnings
warnings.filterwarnings('ignore')

# Load the CSV file
df_distances = pd.read_csv('NBA_Data_Analysis/NBA_results/distance_from_ YEAR <= 2009.csv')

# Define the list of attributes to calculate standard deviation
attributes_list = [
    'Total_distance', 'Age', 'Gam', 'Win', 'Los', 'Poi', 
    'FG%', '3P%', 'FT%', 'Tot', 'Ass', 'Tur', 'Ste', 'Blo', 'Per'
]

# Calculate standard deviations and round to 2 decimal places
deviations = pd.DataFrame({
    "Attribute": attributes_list,
    "Standard_Deviation": [np.std(df_distances[attribute]).round(2) for attribute in attributes_list]
})

# Sort the DataFrame by 'Standard_Deviation' in ascending order
deviations = deviations.sort_values(by='Standard_Deviation')
print("Standard Deviations of Attributes:\n", deviations, "\n")

# Define the dependent (y) and independent variables (X)
X = df_distances[attributes_list[1:]]
y = df_distances['Total_distance']

# Correlation matrix (optional)
# print(df_distances[attributes_list].corr(), "\n")

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the XGBoost model
xg_reg = xgb.XGBRegressor(
    objective='reg:squarederror', 
    colsample_bytree=0.3, 
    learning_rate=0.1,
    max_depth=5, 
    alpha=10, 
    n_estimators=100
)

# Fit the model to the training data
xg_reg.fit(X_train, y_train)

# Make predictions on the test data
y_pred = xg_reg.predict(X_test)

# Calculate the mean squared error (MSE)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.4f}")

# Calculate and display feature importance
feature_importance = pd.DataFrame({
    'Feature': X.columns, 
    'Importance': xg_reg.feature_importances_
}).sort_values(by='Importance', ascending=False)

print("Feature Importances:\n", feature_importance)
